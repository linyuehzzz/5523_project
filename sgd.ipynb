{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sgd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOhF3/T7mF1HlNtqyBBl2Zu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linyuehzzz/5523_project/blob/main/sgd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlILGcNEEW0E"
      },
      "source": [
        "##**Stochastic Gradient Descent for Logistic Regression**\n",
        "This code implements and tests the SGD algorithm for logistic regression\n",
        "in different scenarios.  \n",
        "Yue Lin (lin.3326 at osu.edu)  \n",
        "Created: 11/12/2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGQmKFIeFYKY"
      },
      "source": [
        "#### **Set up libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUex5ElWFaHO"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXnNnylopljK"
      },
      "source": [
        "#### **Project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzHKV3T7pvFo"
      },
      "source": [
        "##### Projection function for hypercube"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ewruRRFp0kP"
      },
      "source": [
        "def cube_prj(sample):\n",
        "  '''\n",
        "  input: a sample with d dimension (1-D array or list)\n",
        "  onput: the euclidean projection of sample\n",
        "  '''\n",
        "  return [np.sign(i) * min(np.abs(i), 1) for i in sample]"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mrnAQvYqI8q"
      },
      "source": [
        "##### Projection function for unit ball"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyUbRJAKqRsd"
      },
      "source": [
        "def ball_prj(sample):\n",
        "    '''\n",
        "    input: a sample with d dimension (1-D array or list)\n",
        "    onput: the euclidean projection of sample\n",
        "    '''\n",
        "    ratio = 1 / np.linalg.norm(sample)\n",
        "    return [i * ratio for i in sample]"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZXfvRgKqXV2"
      },
      "source": [
        "##### Project data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dwzkd6WqW7X"
      },
      "source": [
        "def prj_data(x, y, prj_code):\n",
        "    '''\n",
        "    This function is for conduct projection on data array\n",
        "    x: n*d array (n is sample#, d is dimension)\n",
        "    y: 1-d array with label of -1 or +1\n",
        "    prj_code: type of projection, 0 for cube, 1 for ball\n",
        "    return:\n",
        "        prj_x: projected x \n",
        "        y: same as input\n",
        "    '''\n",
        "    if prj_code == 0:\n",
        "        prj_x = np.apply_along_axis(cube_prj, 1, x)\n",
        "    elif prj_code == 1:\n",
        "        prj_x = np.apply_along_axis(ball_prj, 1, x)\n",
        "    else:\n",
        "        print(\"Please input correct code for projection type: 0 for cube, 1 for ball\")\n",
        "      \n",
        "    b = np.ones((prj_x.shape[0], 1))\n",
        "    prj_x = np.append(prj_x, b, axis=1)\n",
        "    return prj_x, y"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiUQqYKLvAuY"
      },
      "source": [
        "##### Project gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ThWld5kvaBT"
      },
      "source": [
        "def prj_grad(g, prj_code):\n",
        "    '''\n",
        "    This function is for conduct projection on gradients\n",
        "    g: 1-d array (d is dimension)\n",
        "    prj_code: type of projection, 0 for cube, 1 for ball\n",
        "    return:\n",
        "        prj_g: projected gradient\n",
        "    '''\n",
        "    if prj_code == 0:\n",
        "        prj_g = cube_prj(g)\n",
        "    elif prj_code == 1:\n",
        "        prj_g = ball_prj(g)\n",
        "    else:\n",
        "        print(\"Please input correct code for projection type: 0 for cube, 1 for ball\")\n",
        "    return prj_g"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu0jhwwRF5ls"
      },
      "source": [
        "#### **Prepare data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMDzFiFcrsg8"
      },
      "source": [
        "def gen_data(sig, n):\n",
        "    '''\n",
        "    The function is to generate data for training and testing\n",
        "    The feature array is 4 dimension array. \n",
        "     + Each feature follows the Normal distribution(mu,sig)\n",
        "     + with probability 1/2, the y =1 , \n",
        "         generate the correspoinding feature vector from N(mu,sig),mu is [1/4,1/4,1/4,1/4],sig is set as you need.\n",
        "    sig: the sigma of  gussian vector\n",
        "    n: the sample number\n",
        "    \n",
        "    Return:\n",
        "     x: n*d_dimension array\n",
        "     y: 1-d dimension array with -1 and +1\n",
        "    '''\n",
        "    d_dimension = 4\n",
        "    y = np.random.choice([-1, 1], p = [0.5, 0.5], size = n)\n",
        "    x = np.array([])\n",
        "    for i in range(n):\n",
        "        if y[i] == -1:\n",
        "            mu = -(1 / 4)\n",
        "            negvec = np.random.normal(mu, sig, d_dimension)\n",
        "            x = np.concatenate([x, negvec], axis=0)\n",
        "        else:\n",
        "            mu = (1/4)\n",
        "            posvec = np.random.normal(mu, sig, d_dimension)\n",
        "            x = np.concatenate([x,posvec], axis=0)\n",
        "    x = np.reshape(x, (n, d_dimension))\n",
        "    return x, y"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAzwTZ79M6oi"
      },
      "source": [
        "#### **Train**\n",
        "https://machinelearningmastery.com/implement-logistic-regression-stochastic-gradient-descent-scratch-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8XQyQ8Ycqpo"
      },
      "source": [
        "##### Predict using logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzPxwbmIM6NU"
      },
      "source": [
        "# Make a prediction with coefficients\n",
        "def pred(X, w):\n",
        "  yhat = 0.\n",
        "  for i in range(X.shape[0]):\n",
        "    yhat += w[i] * X[i]\n",
        "  yhat = 1.0 / (1.0 + np.exp(-yhat))\n",
        "  if yhat < 0.5:\n",
        "    yhat = -1\n",
        "  else:\n",
        "    yhat = 1 \n",
        "  return yhat"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJfOdxzt4M5T"
      },
      "source": [
        "##### Estimate logistic loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_3nPdw4BJV0"
      },
      "source": [
        "def log_loss(X, y, w):\n",
        "  return np.log(1 + np.exp(-y * np.dot(w.T, X)))"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnfgixZxQqvj"
      },
      "source": [
        "##### Estimate classification error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZdcop9KQuGF"
      },
      "source": [
        "def err(yhat, y):\n",
        "  if yhat == y:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE93wIbQc9Is"
      },
      "source": [
        "##### Estimate weight vector using SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb_QkJsIc8Vh"
      },
      "source": [
        "def train_sgd(train_x, train_y, test_x, test_y, l_rate, n_epoch, bs, prj_code):\n",
        "  w = np.random.uniform(-1, 1, (train_x.shape[1]))\n",
        "  print(w)\n",
        "  risk_all = np.zeros(n_epoch)\n",
        "  cls_err_all = np.zeros(n_epoch)\n",
        "\n",
        "  for epoch in range(n_epoch):\n",
        "    risk = cls_err = grad = 0.\n",
        "    for idx in range(epoch * bs, (epoch + 1) * bs):\n",
        "      # Read data\n",
        "      X = train_x[idx]\n",
        "      y = train_y[idx]\n",
        "      # Calculate gradient\n",
        "      g = (-y * X * np.exp(-y * np.dot(w.T, X)) / (1 + np.exp(-y * np.dot(w.T, X))))\n",
        "      for i in range(train_x.shape[1]):\n",
        "        g[i] = g[i] * X[i]\n",
        "      grad += g\n",
        "\n",
        "    # Project gradient\n",
        "    grad = prj_grad(grad / bs, prj_code)\n",
        "    # Backward propagation\n",
        "    for i in range(train_x.shape[1]):\n",
        "      w[i] = w[i] + l_rate * grad[i]\n",
        "    \n",
        "    # Evaluate\n",
        "    for idx in range(test_x.shape[0]):\n",
        "      # Read data\n",
        "      X = test_x[idx]\n",
        "      y = test_y[idx]\n",
        "      # Predict\n",
        "      yhat = pred(X, w)\n",
        "      # Evaluate\n",
        "      risk += log_loss(X, y, w) / test_x.shape[0]\n",
        "      cls_err += err(yhat, y) / test_x.shape[0]\n",
        "    \n",
        "    np.append(risk_all, risk, axis=None)\n",
        "    np.append(cls_err_all, cls_err, axis=None)\n",
        "    print('>epoch=%d, lrate=%.3f, risk=%.3f, classification error=%.3f' % (epoch, l_rate, risk, cls_err))\n",
        "  \n",
        "  # Report risk\n",
        "  risk_ave = np.average(risk_all)\n",
        "  risk_min = np.amin(risk_all)\n",
        "  risk_var = np.var(risk_all)\n",
        "  exp_excess_risk = risk_ave - risk_min\n",
        "  # Report classification error\n",
        "  cls_err_ave = np.average(cls_err_all)\n",
        "  cls_err_var = np.var(cls_err_all)\n",
        "  return [w, risk_ave, risk_min, risk_var, exp_excess_risk, cls_err_ave, cls_err_var]"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3SH2Dm7d71V"
      },
      "source": [
        "#### **Wrapper**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ68DlKXd6rP",
        "outputId": "8c6edcf7-426d-46a0-8062-fe4391bbf8bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        }
      },
      "source": [
        "# Fixed hyperparameters\n",
        "n_epoch = 30    # training epochs\n",
        "test_n = 400    # size of test set\n",
        "\n",
        "# Unfixed hyperparameters\n",
        "prj_code = 1    # code for two scenario: 0 for cube, 1 for ball\n",
        "l_rate = 0.001  # learning rate\n",
        "train_bs = 50   # batch size for each training epoch\n",
        "sigma = 0.1     # variance of Gaussian distribution\n",
        "\n",
        "# Generate training data\n",
        "train_x, train_y = gen_data(sigma, train_bs * n_epoch)\n",
        "train_px, train_py = prj_data(train_x, train_y, prj_code)\n",
        "\n",
        "# Generate test data\n",
        "test_x, test_y = gen_data(sigma, test_n)\n",
        "test_px, test_py = prj_data(test_x, test_y, prj_code)\n",
        "\n",
        "# Train\n",
        "output = train_sgd(train_px, train_py, test_px, test_py, l_rate, n_epoch, train_bs, prj_code)\n"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.6811076   0.26494992  0.35414407  0.20112446 -0.09472023]\n",
            ">epoch=0, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=1, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=2, lrate=0.001, risk=0.664, classification error=0.373\n",
            ">epoch=3, lrate=0.001, risk=0.665, classification error=0.373\n",
            ">epoch=4, lrate=0.001, risk=0.664, classification error=0.373\n",
            ">epoch=5, lrate=0.001, risk=0.665, classification error=0.373\n",
            ">epoch=6, lrate=0.001, risk=0.665, classification error=0.378\n",
            ">epoch=7, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=8, lrate=0.001, risk=0.665, classification error=0.378\n",
            ">epoch=9, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=10, lrate=0.001, risk=0.664, classification error=0.373\n",
            ">epoch=11, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=12, lrate=0.001, risk=0.665, classification error=0.378\n",
            ">epoch=13, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=14, lrate=0.001, risk=0.664, classification error=0.373\n",
            ">epoch=15, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=16, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=17, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=18, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=19, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=20, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=21, lrate=0.001, risk=0.665, classification error=0.378\n",
            ">epoch=22, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=23, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=24, lrate=0.001, risk=0.665, classification error=0.378\n",
            ">epoch=25, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=26, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=27, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=28, lrate=0.001, risk=0.665, classification error=0.375\n",
            ">epoch=29, lrate=0.001, risk=0.665, classification error=0.375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-181-0e29fb930eaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_px\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_py\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_px\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_py\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_bs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprj_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'w' is not defined"
          ]
        }
      ]
    }
  ]
}